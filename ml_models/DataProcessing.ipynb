{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import argparse\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import re, numpy as np, pandas as pd\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import json\n",
    "from bson import json_util\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import lemmatize\n",
    "\n",
    "import csv\n",
    "\n",
    "import spacy\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "def getData():\n",
    "    df = pd.read_json(r'../backend/data/MedellinCleaned.json')\n",
    "    return df\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "def preprocess(df):\n",
    "    #Remover filas duplicadas\n",
    "    df = df.drop_duplicates(subset=['respuesta'])\n",
    "\n",
    "    #remover espacios extra entre palabras\n",
    "    df['respuesta'] = df['respuesta'].str.replace('  ',' ')\n",
    "    df['respuesta'] = df['respuesta'].str.strip()\n",
    "    #transformar a minuscula\n",
    "    df['respuesta'] = df['respuesta'].str.lower()\n",
    "    #eliminar puntuacion\n",
    "    df['respuesta'] = df['respuesta'].str.replace(r'\\s+', ' ')\n",
    "    df['respuesta'] = df['respuesta'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "\n",
    "    #ods de ods_n como string a n entero\n",
    "    df.ods = [ int(data[data.find('_')+1:])for data in df.ods ]\n",
    "    #meta de meta_ods_n como string a n entero\n",
    "    df.meta = [ data[data.rfind('_')+1:] for data in df.meta ]\n",
    "    return df\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "def process(df):\n",
    "    stop_words = stopwords.words('spanish')\n",
    "    stop_words.extend(['importante','saber','caso','decirlo','esperar','servicio','colombia','decirlo','completamente','encontrar','negocio','respetar','rural','inclusive','loma',\"jovenes\",\"quitar\",\"convivencia\",\"tirar\",\"callar\",\"arbolar\",\"ley\",\"menor\",\"banda\",\"discapacidad\",\"colegiar\",\"creer\",\"lleno\",\"actividad\",\"miedo\",\"vivienda\",\"rios\",\"querer\",\"acabar\",\"venta\",\"citar\",\"responsable\",\"sustanciar\",\"adulto\",\"llenar\",\"dano\",\"verde\",\"ciudadano\",'libre','hablar','andar',\"cultural\",'hijo','cuerpo','visual',\"acceso\",\"auditivo\",\"publicar\",\"esperar\",\"quebrar\",'compromiso','abr','basura','estrato','sustentar','tampoco','seguir','grave','situación','manera','mejorar','poner','hecho','mujer','villanueva','jul','may','aug','nuevo','desarrollar','totalmente','aquejar','general','transicion','casar','clase','necesitar','pensar','sentir','comunicar','conseguir','disfrutar','vendria','vuelta','preferir''darle','mano','alto','claro','bello','buscar','viendo','zonas','tal','podría','afectando','primer','aún','mismos','sólo','digo','aunque','mal','encuentra','cuanto','diferentes','hoy','diría','allá','dejan','arribar','dejar','regar','suceder','valorar','esquinar','mantener','concienciar','solo','vacuno','ayudar','gustar','taco','ninos','jun','ocasionar','evidenciar','pedir','apartar','demorar','aguar','fuerte','inseguro','horas','habitantes','persona','poder','pronto','lugar','empiezan','alguien','presentando','actualmente','saben', 'cosa', 'sido','pues','así','acá','siempre','tan','sector','decir','pasar','mundo','territorio','siendo','varios','verdad','principalmente', 'partes','causa','hacia','sabe','sido','quiere','quién','saben','cosa','sido','tantos', 'salir', 'nunca','calles','visto','mayor','gran','dónde','veo','poca','dice','cada','da','ir','nadie','enfrenta','podemos','casi','menos','cuenta','haciendo','hacen','tipo','bien','digamos','primero','haciendo','cantidad','forma','lado','dar','después','últimamente','mejor','debido','precioso','preferir','quedarse','encerrar','esperar','pensamiento','idolo','sentimiento','aprender','poblador','pico','horrible','realmente','toda','consideró','quedan','siempre','día','problemáticas','cualquier','problemática','día','hora','genera','nivel','falta','principales','presenta','pueden','ejemplo','grande','mala','pasan','ahora','van','considero','manejan','todas','dos','parece','personas','tener','pasan','parte','creo','cuantas','segundo','veces','muchas','tema','personar','medellín','días','ciudad','barrio','gente','problemas','tiene','sector','ser','llegar','presentar','bueno','falto','generar','pues','así','acá','hace','ver','vez','si','generla','cierto','piso','mientras','ahí','cómo','pasando','capacidad','ninguna','tantas','toca','sectores','ven','recogen','va','debería','buenos','sabemos','ciertas','sé','necesita','tan','aquí','sino','años','pertenencia','caminar','prado','deporte','mes','mendicidad','atender','altavista','pie','dificultad','incluso','ve','cosas','puede','afecta','daniel','solamente','edad','barrios','atención','vivir','tolerancia','frente','municipio','comunidad','común','cuidado','vivo','buen','grandes','partir','social','difícil','vida','prueba','dominantData','sacarlo','orden','pueblo','sol','hombre','actual','imposible','intolerancia','tarde','dicho','ahorita','pasa','obviamente','robledo','afectar','pesar','semana','bajar','sale','ninguna','simple','altamente','diferente','margen','comunicación','temas','empresa','derecho','hermano','familiar','constantemente','demasiados','cultura','seguro','mantenimiento','debe','considera','aspectos','poquito','venir','punto','peor','responsabilidad','factor','entorno','llevar','medio','uso','tranquilo','sitio','favor','todavía','cerca','mañana','momentos','apoyo','lleva','considera','mayoría','alrededor','vereda','fácil','presentan','sacan','llegan','necesitamos','grupos','necesidad','puesto','vecino','país','camino','público','vamos','usted','dentro','ponen','segunda','zona','comunas','deben','sociedad','san_cristóbal','san_antonio','acompañamiento','tiempo','bastante','comuna','definitivamente','comuna','dando','buena','buenas','dan','secundario','afectan','mantienen','centro','existe','año','recursos','sacar','calidad','necesidades','corregimiento','malo','vemos','pase','san_cristóbal','belén','lugares','lugar','espacio','espacios','segundo','manejo','queda','tanta','demasiado','tambien','mas','segundar','problema','demás','igual','casas','problemática','entonces','hacer','mucho','quedo','mismo','momento','pienso','principal','mucha'])\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(stop_words))\n",
    "    df['respuesta'] = df['respuesta'].str.replace(pattern, '')\n",
    "\n",
    "    def sent_to_words(sentences):\n",
    "        for sent in sentences:\n",
    "            sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "            yield(sent)  \n",
    "\n",
    "    # Convert to list\n",
    "    data = df.values.tolist()\n",
    "    data_words = list(sent_to_words(data))\n",
    "    # Build the bigram and trigram models\n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "    trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "    # !python3 -m spacy download en  # run in terminal once\n",
    "    def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "        \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "        texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "        texts = [bigram_mod[doc] for doc in texts]\n",
    "        texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "        texts_out = []\n",
    "        nlp = spacy.load(\"es_core_news_sm\")\n",
    "        for sent in texts:\n",
    "            doc = nlp(\" \".join(sent)) \n",
    "            texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "        # remove stopwords once more after lemmatization\n",
    "        texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "        return texts_out\n",
    "\n",
    "    return process_words(data_words)  # processed Text Data!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"success\": true, \"message\": \"Datos cargados\"}\n",
      "{\"success\": true, \"message\": \"Datos preprocesados\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-a096598fa78d>:41: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['respuesta'] = df['respuesta'].str.replace(r'\\s+', ' ')\n",
      "<ipython-input-1-a096598fa78d>:42: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['respuesta'] = df['respuesta'].str.replace('[{}]'.format(string.punctuation), '')\n",
      "<ipython-input-1-a096598fa78d>:54: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['respuesta'] = df['respuesta'].str.replace(pattern, '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"success\": true, \"message\": \"Datos procesados\"}\n",
      "{\"success\": true, \"message\": \"Datos guardados\"}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    numberOfTopics = 10\n",
    "    dotenv.load_dotenv(\".env\")\n",
    "    df = getData()\n",
    "    print('{\"success\": true, \"message\": \"Datos cargados\"}')\n",
    "    df = preprocess(df)\n",
    "    print('{\"success\": true, \"message\": \"Datos preprocesados\"}')\n",
    "    data_ready = process(df)\n",
    "    print('{\"success\": true, \"message\": \"Datos procesados\"}')\n",
    "    df.to_pickle(\"./processedData.pkl\")\n",
    "    with open('data_ready.csv', 'w') as f:\n",
    "        write = csv.writer(f)\n",
    "        write.writerows(data_ready)\n",
    "    print('{\"success\": true, \"message\": \"Datos guardados\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
